{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nJYhe1Er5dC",
        "colab_type": "text"
      },
      "source": [
        "# 距離センサ3つのみでAI RC CARを実現できるか実験してみる。\n",
        "\n",
        "## このノートブックの概要\n",
        "ロボット前方に3つの距離センサを搭載し、AI RC CARと同様に、NNに BCできるかを実験する。\n",
        "\n",
        "## 方針\n",
        "\n",
        "単純な対抗二輪ロボットと距離センサのモデル化を行い、シミュレーション環境とする。まず、単純な比例制御でロボットを制御し、教師データを収集する。収集したデータを３層のNNへ学習させて、走行データをBCさせる。最終的に、比例制御器を学習したNNに置き換えて自動走行が実現できていることを確認する。\n",
        "\n",
        "\n",
        "## シミュレータ環境の構築\n",
        "\n",
        "[詳解 確率ロボティクス]( https://www.amazon.co.jp/dp/4065170060/ref=cm_sw_em_r_mt_dp_U_S8Z9EbWNTEBJ5)で実装されているシミュレータ環境をベースに実装を進める。シミュレータ部分のコード詳細はそちらを参考にする。\n",
        "\n",
        "壁状の障害物を距離センサで検出できるように拡張を行なっている。\n",
        "\n",
        "### Worldクラスの実装\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L0494e8Pcab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "import matplotlib.animation as anm\n",
        "from matplotlib import rc\n",
        "from IPython.display import HTML\n",
        "%matplotlib inline\n",
        "\n",
        "class World:\n",
        "  def __init__(self, time_span, time_interval, debug=False):\n",
        "    self.objects = []\n",
        "    self.debug = debug\n",
        "    self.time_span = time_span\n",
        "    self.time_interval = time_interval\n",
        "\n",
        "  def append(self, obs):\n",
        "    self.objects.append(obs)\n",
        "  \n",
        "  def draw(self):\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlim(-5,5)\n",
        "    ax.set_ylim(-5,5)\n",
        "    ax.set_xlabel(\"X\", fontsize=20)\n",
        "    ax.set_ylabel(\"Y\", fontsize=20)\n",
        "\n",
        "    elems = []\n",
        "    if self.debug:\n",
        "      for i in range(1000): self.one_step(i, elems,ax)\n",
        "    else:\n",
        "      self.ani = anm.FuncAnimation(fig, self.one_step, fargs=(elems,ax), \n",
        "                                   frames=int(self.time_span/self.time_interval), \n",
        "                                   interval = int(self.time_interval * 1000), repeat=False)\n",
        "        \n",
        "  def one_step(self, i, elems, ax):\n",
        "    while elems: elems.pop().remove()\n",
        "    time_str = \"t = %.2f[s]\" % (self.time_interval * i)\n",
        "    elems.append(ax.text(-4.4,4.5, time_str, fontsize=10))\n",
        "    for obj in self.objects:\n",
        "      obj.draw(ax, elems)\n",
        "      if hasattr(obj, \"one_step\"):obj.one_step(self.time_interval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONO1woa10myN",
        "colab_type": "text"
      },
      "source": [
        "### Robotクラスの実装\n",
        "\n",
        "IdealSensorは距離センサのモデル化\n",
        "壁との当たり判定は以下のサイトを参考に実装した。\n",
        "http://konapower.hateblo.jp/entry/2017/09/14/180949"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIqcKE6nPoaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "from scipy.stats import expon, norm\n",
        "\n",
        "class IdealRobot:\n",
        "  def __init__(self, pose, agent=None, sensors=None, color=\"black\"):\n",
        "    self.pose = pose\n",
        "    self.r = 0.2\n",
        "    self.color = color\n",
        "    self.agent = agent\n",
        "    self.poses = [pose]\n",
        "    self.sensor_pose = None\n",
        "    self.sensors = sensors\n",
        "\n",
        "  def draw(self, ax, elems):\n",
        "    x,y,theta = self.pose\n",
        "    xn = x + self.r * math.cos(theta)\n",
        "    yn = y + self.r * math.sin(theta)\n",
        "    self.sensor_pose = np.array([[x, y], [xn, yn]])\n",
        "    elems += ax.plot([x, xn], [y, yn], color = self.color)\n",
        "    c = patches.Circle(xy=(x,y), radius=self.r, fill=False, color = self.color)\n",
        "    elems.append(ax.add_patch(c))\n",
        "    self.poses.append(self.pose)\n",
        "    elems += ax.plot([e[0] for e in self.poses], [e[1] for e in self.poses], linewidth=0.5, color =\"black\")\n",
        "    if len(self.sensors) > 1 and len(self.poses) > 1:\n",
        "      for sensor in self.sensors:\n",
        "        sensor.draw(ax,elems,self.poses[-2])\n",
        "\n",
        "  def one_step(self, time_interval):\n",
        "    if not self.agent:return    \n",
        "    obs = []\n",
        "    for sensor in self.sensors:\n",
        "      obs.append(sensor.data(self.pose))\n",
        "    nu,omega = self.agent.decision(obs)\n",
        "    self.pose = self.state_trantision(nu,omega,time_interval,self.pose)\n",
        "\n",
        "  @classmethod\n",
        "  def state_trantision(cls, nu, omega, time, pose):\n",
        "    t0 = pose[2]\n",
        "    if math.fabs(omega) < 1e-10:\n",
        "      value = np.array([nu*math.cos(t0),\n",
        "                              nu*math.sin(t0),\n",
        "                              omega]) * time\n",
        "      return pose + value\n",
        "    else:\n",
        "      value = np.array([nu/omega*(math.sin(t0 + omega*time) - math.sin(t0)),\n",
        "                              nu/omega*(-math.cos(t0+omega*time)+math.cos(t0)),\n",
        "                              omega*time])\n",
        "      return pose + value\n",
        "\n",
        "class Robot(IdealRobot):\n",
        "\n",
        "  def __init__(self, pose, agent=None, sensors = None, color = \"black\",\n",
        "               noise_per_meter=5, noise_std=math.pi/60,\n",
        "               bias_rate_std=(0.1,0.1)):\n",
        "    super().__init__(pose, agent, sensors, color)\n",
        "    self.noise_pdf = expon(scale=1.0/(1e-100+noise_per_meter))\n",
        "    self.distance_until_noise = self.noise_pdf.rvs()\n",
        "    self.theta_noise = norm(scale=noise_std)\n",
        "    self.bias_rate_nu = norm.rvs(loc=1.0, scale=bias_rate_std[0])\n",
        "    self.bias_rate_omega = norm.rvs(loc=1.0, scale=bias_rate_std[1])\n",
        "\n",
        "  def noise(self, pose, nu, omega, time_interval):\n",
        "    self.distance_until_noise -= abs(nu) * time_interval + self.r * abs(omega) * time_interval\n",
        "    if self.distance_until_noise <= 0.0:\n",
        "      self.distance_until_noise += self.noise_pdf.rvs()\n",
        "      pose[2] += self.theta_noise.rvs()\n",
        "    return pose\n",
        "\n",
        "  def bias(self, nu, omega):\n",
        "    return nu * self.bias_rate_nu, omega * self.bias_rate_omega\n",
        "\n",
        "  def one_step(self, time_interval):\n",
        "    if not self.agent:return    \n",
        "    obs = []\n",
        "    for sensor in self.sensors:\n",
        "      obs.append(sensor.data(self.pose))\n",
        "    nu,omega = self.agent.decision(obs)\n",
        "    nu,omega = self.bias(nu, omega)\n",
        "    self.pose = self.state_trantision(nu, omega, time_interval, self.pose)\n",
        "    self.pose = self.noise(self.pose, nu, omega, time_interval)\n",
        "\n",
        "class IdealRangeSensor:\n",
        "\n",
        "  def __init__(self, env_map, install_angle):\n",
        "    self.env_map = env_map\n",
        "    self.install_angle = install_angle\n",
        "    self.lastdata = []\n",
        "\n",
        "  def data(self, sensor_pose):\n",
        "    observed = []\n",
        "    ls = self.line_segment(sensor_pose)\n",
        "    for w in self.env_map.walls:\n",
        "      p = self.intersection(ls[0], ls[1], w.points[0], w.points[1])\n",
        "      observed.append(p)\n",
        "    self.lastdata = self._select_min_distance(np.array(observed))\n",
        "    return self.lastdata\n",
        "\n",
        "  def _select_min_distance(self, observed):\n",
        "    np.argsort(observed[:, 2])\n",
        "    a_2d_sort_col_num = observed[np.argsort(observed[:, 2])]\n",
        "    return a_2d_sort_col_num[0]\n",
        "  \n",
        "  def line_segment(self, sensor_pose):\n",
        "    x,y,theta = sensor_pose\n",
        "    corners = np.array([[5, 5], [5,- 5], [-5, 5], [-5, -5]])\n",
        "    l = max([math.hypot(*(np.array([x, y]-corner))) for corner in corners])\n",
        "    nx = x + l * math.cos(theta+self.install_angle)\n",
        "    ny = y + l * math.sin(theta+self.install_angle)\n",
        "    return np.array([[x, y], [nx, ny]])\n",
        "\n",
        "  def intersection(self, p1,p2,p3,p4):\n",
        "    ab = p2-p1; ac = p3-p1; cd = p4-p3\n",
        "    c = np.cross(ab,cd)\n",
        "    if c != 0:\n",
        "      r1 = np.cross(ac,ab)/c\n",
        "      r2 = np.cross(ac,cd)/c\n",
        "      if 0 <= r1 and r1 <= 1and 0 <= r2 and r2 <= 1:\n",
        "        position = (ab*r2)+p1\n",
        "        diff = p1 - position  \n",
        "        distance = np.hypot(*diff)\n",
        "        return np.array([position[0], position[1], distance])\n",
        "    return np.array([float('inf'), float('inf'), float('inf')])\n",
        "    \n",
        "  def draw(self, ax, elems, sensor_pose):\n",
        "    x,y,theta = sensor_pose\n",
        "    if len(self.lastdata) > 0:\n",
        "      elems += ax.plot([x,self.lastdata[0]],[y,self.lastdata[1]], color=\"pink\")\n",
        "\n",
        "class RangeSensor(IdealRangeSensor):\n",
        "  def __init__(self, env_map,\n",
        "               install_angle,\n",
        "               distance_noise_rate=0.1):\n",
        "    super().__init__(env_map, install_angle)\n",
        "    self.distance_noise_rate = distance_noise_rate\n",
        "\n",
        "  def noise(self, relpose):\n",
        "    ell = norm.rvs(loc=relpose[2], scale=relpose[2]*self.distance_noise_rate)\n",
        "    return np.array([relpose[0],relpose[1],ell]).T\n",
        "\n",
        "  def data(self, sensor_pose):\n",
        "    observed = []\n",
        "    ls = self.line_segment(sensor_pose)\n",
        "    for w in self.env_map.walls:\n",
        "      p = self.intersection(ls[0], ls[1], w.points[0], w.points[1])\n",
        "      observed.append(p)\n",
        "    self.lastdata = self._select_min_distance(np.array(observed))\n",
        "    self.lastdata = self.noise(self.lastdata)\n",
        "    return self.lastdata\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-DmVO-RD1DO",
        "colab_type": "text"
      },
      "source": [
        "### 壁とマップクラスの実装\n",
        "\n",
        "障害物として壁を定義、２点間の線分として表現する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVTxQhpsXhub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Wall:\n",
        "  def __init__(self,p1,p2):\n",
        "    self.points = np.vstack([p1,p2])\n",
        "    self.id = None\n",
        "  \n",
        "  def draw(self, ax, elems):\n",
        "    elems += ax.plot([e[0] for e in self.points], \n",
        "                     [e[1] for e in self.points], color=\"blue\",linewidth=0.5)\n",
        "    \n",
        "class Map:\n",
        "  def __init__(self):\n",
        "    self.walls=[]\n",
        "  def append_walls(self, wall):\n",
        "    wall.id = len(self.walls) + 1\n",
        "    self.walls.append(wall)\n",
        "  \n",
        "  def draw(self, ax, elems):\n",
        "    for w in self.walls: w.draw(ax,elems)\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV1OdbsyD4jA",
        "colab_type": "text"
      },
      "source": [
        "### Agentクラス実装\n",
        "\n",
        "Agentクラスは右センサ、左センサの差分を入力として比例制御を行う、左右のセンサの値が同じになる（コース中央を通る）ように制御を行う。速度は今の所固定。比例制御のパラメータはヒューリスティックに適当に決定。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpOsapmqRwvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self,nu,omega):\n",
        "    self.nu = nu\n",
        "    self.omega = omega\n",
        "    self.record = []\n",
        "    self.kp = 20\n",
        "  \n",
        "  def decision(self, observation=None):\n",
        "    e = (observation[2][2] - observation[1][2]) * self.kp\n",
        "    self.omega = (e / 180 * math.pi) # 角度指令omegaに対する制御\n",
        "    #速度指令は初期値で固定、実際は上記制御に加えて速度制御用の式が必要になる。\n",
        "    self.record.append([observation[0][2],observation[1][2],observation[2][2], self.omega, self.nu]) # 学習データの記録、入力とそれに対応する出力をセットで記録する。\n",
        "    return self.nu, self.omega\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-tB7SZkLzuV",
        "colab_type": "text"
      },
      "source": [
        "## シミュレーションの実行\n",
        "\n",
        "Google Colabではリアルタイムの表示ができないため、動画で確認。実行は結構時間かかる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMDNt8bTPsA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time = 300 #シミュレーション時間\n",
        "interval = 0.1 #制御周期(10Hz)\n",
        "world=World(time, interval)\n",
        "\n",
        "#外壁\n",
        "w1 = Wall([-3.5, -3],[-3.5, 3])\n",
        "w2 = Wall([-3.5, 3],[-2.5, 4])\n",
        "w3 = Wall([-2.5,4],[2.5,4])\n",
        "w4 = Wall([2.5,4],[3.5,3])\n",
        "w5 = Wall([3.5, 3],[3.5,-3])\n",
        "w6 = Wall([3.5,-3],[2.5,-4])\n",
        "w7 = Wall([2.5,-4],[-2.5,-4])\n",
        "w8 = Wall([-2.5,-4],[-3.5,-3])\n",
        "\n",
        "#内壁\n",
        "w9 = Wall([-2, -1.5],[-2, 1.5])\n",
        "w10 = Wall([-2,1.5],[-1,2.5])\n",
        "w11 = Wall([-1,2.5],[1,2.5])\n",
        "w12 = Wall([1, 2.5],[2,1.5])\n",
        "w13 = Wall([2, 1.5],[2,-1.5])\n",
        "w14 = Wall([2,-1.5],[1,-2.5])\n",
        "w15 = Wall([1,-2.5],[-1,-2.5])\n",
        "w16 = Wall([-1,-2.5],[-2, -1.5])\n",
        "\n",
        "map = Map()\n",
        "map.append_walls(w1)\n",
        "map.append_walls(w2)\n",
        "map.append_walls(w3)\n",
        "map.append_walls(w4)\n",
        "map.append_walls(w5)\n",
        "map.append_walls(w6)\n",
        "map.append_walls(w7)\n",
        "map.append_walls(w8)\n",
        "map.append_walls(w9)\n",
        "map.append_walls(w10)\n",
        "map.append_walls(w11)\n",
        "map.append_walls(w12)\n",
        "map.append_walls(w13)\n",
        "map.append_walls(w14)\n",
        "map.append_walls(w15)\n",
        "map.append_walls(w16)\n",
        "\n",
        "agent = Agent(0.6, 0.0)\n",
        "front_sensor = RangeSensor(map, 0)\n",
        "right_sensor = RangeSensor(map, -math.pi/6)\n",
        "left_sensor = RangeSensor(map, math.pi/6)\n",
        "sensors = [front_sensor, right_sensor, left_sensor]\n",
        "robot1 = Robot(np.array([-2.5, 0, math.pi/2]).T, agent, sensors)\n",
        "world.append(map)\n",
        "world.append(robot1)\n",
        "world.draw()\n",
        "rc('animation', html='jshtml')\n",
        "world.ani\n",
        "#print(len(agent.record))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW06zNf-FGcs",
        "colab_type": "text"
      },
      "source": [
        "## \b学習データの準備\n",
        "\n",
        "学習データはagent.recordにリストとして溜まっている。以下の並びのデータが収集されている。\n",
        "\n",
        "\n",
        "```[中央センサの値,右センサの値,左センサの値,舵角,速度]```\n",
        "\n",
        "以下ではPytorchで学習させるためにデータの整形と変換を行う。正規化とかしてないけど多分動く。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjWOuLjblILs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "x = np.array(agent.record)\n",
        "\n",
        "# xを2個の配列に水平分割\n",
        "train_data, train_labels = np.hsplit(x, [3])\n",
        "\n",
        "print(train_data)\n",
        "print(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RvX55jkFoe_",
        "colab_type": "text"
      },
      "source": [
        "## NNのモデル定義\n",
        "\n",
        "NNのネットワークを構築する。入力3,出力2の全結合3層のニューラルネットワーク、口が裂けても深層学習とか言ってはいけない。入力3はセンサの値をそのまま突っ込む。出力２は速度と舵角が出力される。中間層は16あるけど、多分、さらに半分に落としても問題ない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkpRbuG6kNf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation='relu', input_shape=(3,)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(2),\n",
        "  ])\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='mse',\n",
        "              optimizer = optimizer,\n",
        "              metrics = ['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3sBV5fzGFoN",
        "colab_type": "text"
      },
      "source": [
        "## 学習ループ\n",
        "\n",
        "Tensorflowの学習ループ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-6fer1Ro1ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(\n",
        "  train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=1,\n",
        "  callbacks=[])\n",
        "print(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNJag7QHUv6",
        "colab_type": "text"
      },
      "source": [
        "## 学習モデルを利用した制御関数の実装\n",
        "\n",
        "学習済みのモデルを使って制御を行う。Agentクラスの比例制御を```model(o)```で置き換えるだけで実装が終わる。\n",
        "つまり、線形比例の制御関数を大量のデータを学習したNNで近似したことになる。回帰学習だから当たり前なんだけど、ある種本質をついている結果だと思う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyfHx4kFpQdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepAgent:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  def decision(self, observation=None):\n",
        "    o = np.array([[observation[0][2],observation[1][2],observation[2][2]]])\n",
        "    result = model.predict(o).flatten()\n",
        "    return np.array(result[1]), np.array(result[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWFLDBsLHTYC",
        "colab_type": "text"
      },
      "source": [
        "## 学習済みモデルによる自動走行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faY_pVP0--bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mapやセンサの定義は学習時のオブジェクトを使い回す。\n",
        "\n",
        "world=World(150, 0.1)\n",
        "deep_agent = DeepAgent(model)\n",
        "robot = Robot(np.array([-3, 0, math.pi/2]).T, deep_agent, sensors)\n",
        "world.append(map)\n",
        "world.append(robot)\n",
        "world.draw()\n",
        "rc('animation', html='jshtml')\n",
        "world.ani"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFlfw3eUYBwu",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow lite for microcontrollerへモデル変換\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOzSTGS1WAnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert() #量子化はせずFP32のまま処理していことに注意!\n",
        "\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "\n",
        "!apt-get install xxd\n",
        "!xxd -i converted_model.tflite > airc_model.cpp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcK2csDTZ021",
        "colab_type": "text"
      },
      "source": [
        "## Download FlatBuffer C files.\n",
        "\n",
        "TensorFlow lite for microcontroller向けに保存したモデルファイルをダウンロードする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbwyTPoYU8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('airc_model.cpp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO_IV6qjaP1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "simple-airccar-simulation-tensorflow-keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}